{"cells":[{"cell_type":"markdown","metadata":{"id":"fkoF-mm8CGfB"},"source":["# Credits:  https://github.com/anothermartz/"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"lvmg_zr-9yaZ","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689752903896,"user_tz":-330,"elapsed":81911,"user":{"displayName":"Mohit Gupta","userId":"16760359733823311435"}},"outputId":"19d9384a-0485-4812-c1e9-5bd4f28f4c37"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Installation complete, move to Step 2!\n","Execution time: 1m 1s\n"]}],"source":["#@title <h1>Step 1: Setup</h1>\n","#@markdown Run this cell to mount Google Drive, install Wav2Lip from https://github.com/anothermartz/\n","#check if already installed\n","import os\n","import sys\n","if os.path.exists('/content/Easy-Wav2Lip/installed.txt'):\n","  sys.exit('Step 1 has already been run in this instance! If you want to reinstall go to Runtime > Disconnect and delete runtime')\n","#mount Google Drive\n","print(\"Mounting Google Drive...\")\n","GDrive = True\n","from google.colab import drive\n","try:\n","  drive.mount('/content/drive')\n","  print(\"You should look for your video in the file browser now while the rest is installing\")\n","except:\n","  from IPython.core.display import clear_output\n","  clear_output()\n","  print(\"...Not mounting Google Drive \\n You should start uploading your video(s) now\")\n","  GDrive = False\n","\n","print()\n","print('Downloading and installing requirements - this usually takes 2-3 minutes, scroll down and start setting up Step 2!')\n","print()\n","\n","import time\n","start_time = time.time()\n","\n","import warnings\n","\n","import tensorflow as tf\n","import torch\n","import sys\n","#check GPU\n","print(\"Checking GPU is enabled:\")\n","if not tf.test.gpu_device_name():\n","    sys.exit('No GPU in runtime. Please go to the \"Runtime\" menu, \"Change runtime type\" and select \"GPU\".')\n","else:\n","  gpu_name = torch.cuda.get_device_name(0)\n","  gpu_name = gpu_name.replace(' ', '_')\n","  print(f'GPU is {gpu_name}')\n","\n","#imports and stuff\n","import csv\n","import gdown\n","import io\n","import json\n","import pandas as pd\n","import re\n","import requests\n","import shutil\n","import subprocess\n","\n","from base64 import b64encode\n","from numpy.lib import stride_tricks\n","from IPython.display import HTML, Audio, clear_output\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.exceptions import DataConversionWarning\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","!git clone -b v4 --single-branch https://github.com/anothermartz/Easy-Wav2Lip.git\n","os.chdir('Easy-Wav2Lip')\n","os.system('pip3 install -r requirements.txt')\n","from wav2lip_models import Wav2Lip\n","from basicsr.utils.download_util import load_file_from_url\n","from face_parsing import init_parser\n","def load_model(path):\n","    model = Wav2Lip()\n","    print(\"Load checkpoint from: {}\".format(path))\n","    checkpoint = torch.load(path)\n","    s = checkpoint[\"state_dict\"]\n","    new_s = {}\n","    for k, v in s.items():\n","        new_s[k.replace('module.', '')] = v\n","    model.load_state_dict(new_s)\n","    model = model.to(\"cuda\")\n","    return model.eval()\n","!pip install boto3 --quiet\n","!pip install realesrgan --quiet\n","#clear_output()\n","import boto3\n","from botocore.exceptions import NoCredentialsError\n","#!python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_gfpgan.mp4\" --resize_factor 8 --no_sr\n","#!python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_gfpgan.mp4\" --resize_factor 8 --enhance_face 'gfpgan'\n","\n","codeformer_initialized = False\n","ESRGAN_initialized = False\n","#!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O '/content/Easy-Wav2Lip/checkpoints/wav2lip_gan.pth'\n","#!wget \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\" -O \"/weights/RealESRGAN_x4plus.pth\"\n","#!wget \"https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/realesr-general-x4v3.pth\" -O \"/weights/realesr-general-x4v3.pth\"\n","#!wget 'https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/wav2lip.pth' -O '/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth'\n","#!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\"\n","#clear_output()\n","\n","from esrgan.upsample import load_sr\n","from basicsr.utils.download_util import load_file_from_url\n","import torch, face_detection\n","\n","face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device='cuda')\n","\n","device = 'cuda'\n","\n","def _load(checkpoint_path):\n","    if device == 'cuda':\n","        checkpoint = torch.load(checkpoint_path)\n","    else:\n","        checkpoint = torch.load(checkpoint_path,\n","                                map_location=lambda storage, loc: storage)\n","    return checkpoint\n","\n","def load_model(path):\n","    model = Wav2Lip()\n","    print(\"Load checkpoint from: {}\".format(path))\n","    checkpoint = _load(path)\n","    s = checkpoint[\"state_dict\"]\n","    new_s = {}\n","    for k, v in s.items():\n","        new_s[k.replace('module.', '')] = v\n","    model.load_state_dict(new_s)\n","\n","    model = model.to(device)\n","    return model.eval()\n","\n","print(\"Loading segmentation network...\")\n","seg_net = load_file_from_url(\n","  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/face_segmentation.pth',\n","  model_dir='checkpoints', progress=True, file_name=None)\n","seg_net = init_parser('checkpoints/face_segmentation.pth')\n","print(\"Loading super resolution model...\")\n","load_file_from_url(\n","  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/4x_BigFace_v3_Clear.pth',\n","  model_dir='weights', progress=True, file_name=None)\n","run_params = load_sr('weights/4x_BigFace_v3_Clear.pth', 'cuda', 'gfpgan')\n","\n","model_path = load_file_from_url(\n","  url='https://github.com/anothermartz/Easy-Wav2Lip/releases/download/Prerequesits/Wav2Lip.pth',\n","  model_dir='checkpoints', progress=True, file_name='Wav2Lip.pth')\n","model = load_model('/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth')\n","print (\"Model loaded\")\n","\n","\n","#---------------------------------functions!------------------------------------\n","\n","def showVideo(file_path):\n","  \"\"\"Function to display video in Colab\"\"\"\n","  mp4 = open(file_path,'rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","  display(HTML(\"\"\"\n","  <video controls width=600>\n","      <source src=\"%s\" type=\"video/mp4\">\n","  </video>\n","  \"\"\" % data_url))\n","\n","def get_video_details(filename):\n","    cmd = ['ffprobe', '-v', 'error', '-show_format', '-show_streams', '-of', 'json', filename]\n","    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","    info = json.loads(result.stdout)\n","\n","    # Get video stream\n","    video_stream = next(stream for stream in info['streams'] if stream['codec_type'] == 'video')\n","\n","    # Get resolution\n","    width = int(video_stream['width'])\n","    height = int(video_stream['height'])\n","    resolution = width*height\n","\n","    # Get fps\n","    fps = eval(video_stream['avg_frame_rate'])\n","\n","    # Get length\n","    length = float(info['format']['duration'])\n","\n","    return {'resolution': resolution, 'fps': fps, 'length': length}\n","\n","def predict_processing_time(input_resolution, input_fps, input_length, resolution_scale, upscaler):\n","    filename = f'{upscaler}_with_{gpu_name}_ProcessingStats.csv'\n","    try:\n","        # Load the data from the CSV file\n","        data = pd.read_csv(filename, header=None)\n","    except FileNotFoundError:\n","        return None\n","\n","    # Split the data into input features and target variable\n","    X = data.iloc[:, :-1]\n","    y = data.iloc[:, -1]\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","    # Train a random forest regressor on the training data\n","    regressor = RandomForestRegressor()\n","    regressor.fit(X_train, y_train)\n","\n","    # Calculate the R-squared value on the test set\n","    r_squared = regressor.score(X_test, y_test)\n","\n","    # Create a new row of data for the new video\n","    new_video = [input_resolution, input_fps, input_length, resolution_scale]\n","\n","    # Predict the processing time of the new video\n","    predicted_time = regressor.predict([new_video])\n","\n","    return predicted_time, r_squared\n","\n","def format_time(seconds):\n","    hours = int(seconds // 3600)\n","    minutes = int((seconds % 3600) // 60)\n","    seconds = int(seconds % 60)\n","\n","    if hours > 0:\n","        return f'{hours}h {minutes}m {seconds}s'\n","    elif minutes > 0:\n","        return f'{minutes}m {seconds}s'\n","    else:\n","        return f'{seconds}s'\n","\n","def store_processing_stats(filename, input_resolution, input_fps, input_length, resolution_scale, upscaler, process_time):\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([input_resolution, input_fps, input_length, resolution_scale, process_time])\n","\n","def get_input_length(filename):\n","    result = subprocess.run(\n","        [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n","         \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename],\n","        stdout=subprocess.PIPE,\n","        stderr=subprocess.STDOUT)\n","    return float(result.stdout)\n","\n","def count_lines(stats_file):\n","    with open(stats_file, 'r') as f:\n","        return sum(1 for line in f)\n","\n","def remove_duplicates(stats_file):\n","    df = pd.read_csv(stats_file)\n","    df = df.drop_duplicates()\n","    df.to_csv(stats_file, index=False)\n","\n","def is_url(string):\n","    url_regex = re.compile(r'^(https?|ftp)://[^\\s/$.?#].[^\\s]*$')\n","    return bool(url_regex.match(string))\n","\n","def getkeys():\n","    import gdown\n","    import zipfile\n","    import os\n","    import boto3\n","    url = 'https://drive.google.com/uc?id=1nXL-wQ2B9sxny9TwjWAKwQRi7Rs-Pmis'\n","    zip_path = '/content/Easy-Wav2Lip/temp/pdata.zip'\n","    gdown.download(url, zip_path, quiet=True)\n","    txt_path = '/content/Easy-Wav2Lip/temp/pdata.txt'\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall('/content/Easy-Wav2Lip/temp/')\n","    with open(txt_path, 'r') as f:\n","        lines = f.readlines()\n","        s3_folder = lines[0].strip()\n","        s3_access_key = lines[1].strip()\n","        s3_secret_key = lines[2].strip()\n","        bucket_name = lines[3].strip()\n","    os.remove(zip_path)\n","    os.remove(txt_path)\n","    s3 = boto3.client('s3', aws_access_key_id=s3_access_key, aws_secret_access_key=s3_secret_key)\n","    return s3, s3_folder, bucket_name\n","\n","s3, s3_folder, bucket_name = getkeys()\n","################################################################################\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","formatted_setup_time = format_time(elapsed_time)\n","with open('installed.txt', 'w') as f:\n","    f.write('Wav2Lip has been installed.')\n","clear_output()\n","print()\n","print(\"Installation complete, move to Step 2!\")\n","print(f\"Execution time: {formatted_setup_time}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"49bpPc22f-wR","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"error","timestamp":1689754168340,"user_tz":-330,"elapsed":570751,"user":{"displayName":"Mohit Gupta","userId":"16760359733823311435"}},"outputId":"3177a7c7-f7ee-4fca-df13-5db66f46e9a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["5_poi_720p_vid_768_1500_5_poi_aud_768_1500 successfully lip synced! Find it in the same folder as your input file(s).\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-cb2c6cfcdcb2>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output_filename} successfully lip synced! Find it in the same folder as your input file(s).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpredicted_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Predicted processing time for this video was: {formatted_time} {confidence}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Actual Processing time: {formatted_process_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'predicted_time' is not defined"]}],"source":["import os\n","import sys\n","if not os.path.exists('/content/Easy-Wav2Lip/installed.txt'):\n","  sys.exit('Step 1 has not been run in this instance! Please run step 1 each time you disconnect from a runtime.')\n","\n","############################## user inputs #####################################\n","#@markdown <h1>Step 2: Select inputs:</h1>\n","\n","#@markdown On destktop: <h1></h1>Click the folder icon ( 📁 ) at the left edge of colab, find your video, right click, copy path, paste it below:\n","#@markdown<br></br>\n","#@markdown On mobile: <h1></h1>Tap the hamburger button ( ☰ ) at the top left, click show file browser, long tab (hold) on Easy-Wav2Lip, upload, select your file(s), find them in the file browser, copy path, paste below:\n","video_or_image = \"/content/drive/MyDrive/wav2lip_a/processed_outputs2/5_poi_720p_vid_768_1500.mp4\" #@param {type:\"string\"}\n","vocal_track = \"/content/drive/MyDrive/wav2lip_a/processed_outputs2/5_poi_aud_768_1500.wav\" #@param {type:\"string\"}\n","#@markdown > Keep vocal_track blank if your video already has the desired speech audio encoded into it\n","#@markdown\n","#@markdown <br>\n","\n","#@markdown ---\n","\n","#@markdown<br><br>\n","#@markdown <br>\n","\n","#@markdown # [Advanced tweaking](https://github.com/anothermartz/Easy-Wav2Lip#advanced-tweaking) (optional) </h1>Just scroll past all of this if you are new, or click the blue titles for instructions.\n","#@markdown <br>\n","\n","#@markdown ### [Upscaling:](https://github.com/anothermartz/Easy-Wav2Lip#upscaling)\n","upscaler = \"gfpgan\" #@param [\"no_upscaling\", \"gfpgan\", \"codeformer\", \"ESRGAN\"]\n","if upscaler == \"codeformer\" and codeformer_initialized==False: # do an initial video process on a tiny file so that downloads don't affect processing time\n","  !python inference.py --face \"/content/Easy-Wav2Lip/wow.mp4\" --audio \"/content/Easy-Wav2Lip/wow.wav\" --outfile \"/content/Easy-Wav2Lip/initialize/initialized_codeformer.mp4\" --resize_factor 8 --enhance_face 'codeformer'\n","  codeformer_initialized = True\n","##@markdown  > I've found that \"gfpgan\" always gives the best results but maybe other models work better for other content. <br> For the fastest processing time use \"no_upscaling\".\n","default_ESRGAN_model = \"/content/Easy-Wav2Lip/weights/weights/4x_BigFace_v3_Clear.pth\"\n","ESRGAN_model = \"/content/Easy-Wav2Lip/weights/weights/4x_BigFace_v3_Clear.pth\" #@param [\"/content/Easy-Wav2Lip/weights/RealESRGAN_x4plus.pth\"] {allow-input: true}\n","if upscaler == \"ESRGAN\":\n","  if not os.path.exists(ESRGAN_model):\n","    sys.exit(\"ESRGAN_model specified is not found\")\n","##@markdown  > For use with 'ESRGAN' option only.\n","codeformer_fidelity = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n","##@markdown > For use with 'codeformer' option only.\n","#@markdown <br></br>\n","#@markdown ### [Padding:](https://github.com/anothermartz/Easy-Wav2Lip#tweak-padding)</h1> (Up, Down, Left, Right) <br>\n","U = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n","D = 10 #@param {type:\"slider\", min:-40, max:100, step:5}\n","L = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n","R = 0 #@param {type:\"slider\", min:-40, max:100, step:5}\n","#@markdown <br></br>\n","#@markdown # [Batch Processing:](https://github.com/anothermartz/Easy-Wav2Lip#batch-processing)\n","batch_process = False #@param {type:\"boolean\"}\n","#@markdown <br></br>\n","#@markdown # [Other options:](https://github.com/anothermartz/Easy-Wav2Lip#other-options)\n","resolution_scale =  0.5 #@param {type:\"slider\", min:0.25, max:1, step:0.25}\n","fps_for_static_image = 25 #@param {type:\"number\"}\n","nosmooth = True #@param {type:\"boolean\"}\n","output_suffix = \"_v1_2_EasyWav2Lip\" #@param {type:\"string\"}\n","include_upscaler_in_suffix = True #@param {type:\"boolean\"}\n","if include_upscaler_in_suffix:\n","  if upscaler==\"ESRGAN\":\n","    output_suffix = output_suffix + \"_\" + re.search(r\"[^\\/]+(?=\\.\\w+$)\", ESRGAN_model).group()\n","  elif upscaler==\"codeformer\":\n","    output_suffix = f'{output_suffix}_{upscaler}_' + str(codeformer_fidelity).replace(\".\", \"_\")\n","  else:\n","    output_suffix = f'{output_suffix}_{upscaler}'\n","preview_input = True #@param {type:\"boolean\"}\n","#------------------------------*Step 3*----------------------------------------!\n","#@markdown <h1><br>👈 Step 3:  Click the little circle play button on this cell! </h1> (Or press ctrl + F10) - Then wait for processing to complete.\n","# scale padding with resolution\n","rescaleFactor = str(round(1 // resolution_scale))\n","pad_up = str(round(U * resolution_scale))\n","pad_down = str(round(D * resolution_scale))\n","pad_left = str(round(L * resolution_scale))\n","pad_right = str(round(R * resolution_scale))\n","################################################################################\n","\n","\n","######################### reconstruct input paths ##############################\n","# check video_or_image exists\n","if not os.path.exists(video_or_image):\n","  sys.exit(f'Could not find file: {video_or_image}')\n","# extract each part of the path\n","filename = re.search(r\"[^\\/]+(?=\\.\\w+$)\", video_or_image).group()\n","file_type = os.path.splitext(video_or_image)[1]\n","folder = re.search(r\"^(.*\\/)[^\\/]+$\", video_or_image).group(1)\n","filenumber_match = re.search(r\"\\d+$\", filename)\n","if filenumber_match: # if there is a filenumber - extract it\n","  filenumber = str(filenumber_match.group())\n","  filenamenonumber = re.sub(r\"\\d+$\", \"\", filename)\n","else: # if there is no filenumber - make it blank\n","  filenumber = \"\"\n","  filenamenonumber = filename\n","\n","# if vocal_track is blank - use the video as audio\n","if vocal_track == \"\":\n","  vocal_track = video_or_image\n","# if not, check that the vocal_track file exists\n","else:\n","  if not os.path.exists(vocal_track):\n","    sys.exit(f'Could not find file: {vocal_track}')\n","# extract each part of the path:\n","audio_filename = re.search(r\"[^\\/]+(?=\\.\\w+$)\", vocal_track).group()\n","audio_file_type = os.path.splitext(vocal_track)[1]\n","audio_folder = re.search(r\"^(.*\\/)[^\\/]+$\", vocal_track).group(1)\n","audio_filenumber_match = re.search(r\"\\d+$\", audio_filename)\n","if audio_filenumber_match: #if there is a filenumber - extract it\n","  audio_filenumber = str(audio_filenumber_match.group())\n","  audio_filenamenonumber = re.sub(r\"\\d+$\", \"\", audio_filename)\n","else: # if there is no filenumber - make it blank\n","  audio_filenumber = \"\"\n","  audio_filenamenonumber = audio_filename\n","################################################################################\n","\n","# set process_failed to False so that it may be set to True if one or more processings fail\n","process_failed = False\n","temp_output = '/content/Easy-Wav2Lip/temp/output.mp4'\n","temp_folder = '/content/Easy-Wav2Lip/temp/'\n","last_input_video = None\n","last_input_audio = None\n","\n","#if file_type == '.gif':\n","#  sys.exit(\"I'm sorry but .gif files aren't supported!\")\n","\n","#if file_type == '.jpg' or '.jpeg' or '.png' or '.bmp' or '.tiff' or '.tif':\n","#  input_is_image = True\n","#else:\n","#  input_is_image = False\n","\n","\n","#--------------------------Batch processing loop-------------------------------!\n","while True:\n","\n","  # construct input_video\n","  input_video = folder + filenamenonumber + str(filenumber) + file_type\n","  input_videofile = re.search(r\"[^\\/]+$\", input_video).group()\n","  # construct input_audio\n","  input_audio = audio_folder + audio_filenamenonumber + str(audio_filenumber) + audio_file_type\n","  input_audiofile = re.search(r\"[^\\/]+$\", input_audio).group()\n","  # see if filenames are different:\n","  if filenamenonumber + str(filenumber) != audio_filenamenonumber + str(audio_filenumber):\n","    output_filename = filenamenonumber + str(filenumber) + \"_\" + audio_filenamenonumber + str(audio_filenumber)\n","  else:\n","    output_filename = filenamenonumber + str(filenumber)\n","  # construct output_video\n","  output_video = folder + output_filename + output_suffix + '.mp4'\n","  output_videofile = re.search(r\"[^\\/]+$\", output_video).group()\n","\n","  # remove last outputs\n","  directory_path = \"/content/Easy-Wav2Lip/temp\"\n","  if os.path.exists(directory_path):\n","    shutil.rmtree(directory_path)\n","  os.makedirs(directory_path)\n","\n","  # preview inputs (if enabled)\n","  if preview_input:\n","    print(\"input video:\")\n","    showVideo(input_video)\n","    if vocal_track != \"\":\n","      print(\"input audio:\")\n","      display(Audio(input_audio))\n","    else:\n","      print(\"using\", input_video, \"for audio\")\n","    print(\"You may want to check now that they're the correct files!\")\n","\n","  #------------------------process length prediction---------------------------!\n","  num_lines = 1\n","  stats_file = f'{upscaler}_with_{gpu_name}_ProcessingStats_v4.csv'\n","  try:\n","    details = get_video_details(input_video)\n","    input_resolution = int(details['resolution'])\n","    input_fps = int(details['fps'])\n","    input_length = float(details['length'])\n","    new_video_resolution = input_resolution\n","    new_video_fps = input_fps\n","    new_video_length = input_length\n","    new_video_resolution_scale = resolution_scale\n","    new_video_upscaler = upscaler\n","    object_key = 'wav2lip/' + stats_file\n","    input_is_image = False\n","  except:\n","    try:\n","      from PIL import Image\n","      image = Image.open(input_video)\n","      width, height = image.size\n","      input_resolution = width * height\n","      input_fps = fps_for_static_image\n","      input_length = get_input_length(input_audio)\n","      stats_file = f'{upscaler}_with_{gpu_name}_image_ProcessingStats_v4.csv'\n","      new_video_resolution = input_resolution\n","      new_video_fps = input_fps\n","      new_video_length = input_length\n","      new_video_resolution_scale = resolution_scale\n","      new_video_upscaler = upscaler\n","      object_key = 'wav2lip/' + stats_file\n","      input_is_image = True\n","    except:\n","      print(\"Unable to get video/image details\")\n","  try:\n","      s3.head_object(Bucket=bucket_name, Key=object_key)\n","      s3.download_file(bucket_name, object_key, stats_file)\n","      print(f\"Found prediction data for {gpu_name} with {upscaler} {'(image)' if input_is_image else '(video)'} \")\n","      remove_duplicates(stats_file)\n","      num_lines = count_lines(stats_file)\n","      if num_lines < 10:\n","        print('But there isn\\'t enough prediction data for that combo yet to predict a processing time')\n","        predicted_time = None\n","  except:\n","      predicted_time = None\n","      print(f\"No prediction data for {gpu_name} with {upscaler} yet\")\n","  if num_lines > 9:\n","    try:\n","      predicted_time, r_squared = predict_processing_time(input_resolution, input_fps, input_length, resolution_scale, upscaler)\n","      if r_squared <0:\n","        print('Not much prediction data so prediction is unlikely to be accurate, but the more people process videos, the better it will get!')\n","      if predicted_time is not None:\n","        formatted_time = format_time(predicted_time[0])\n","        confidence = '(~' + str(max(int(r_squared * 100),1)) + \"% confidence)\"\n","        print()\n","        print(f'Predicted processing time for this video is: {formatted_time} {confidence}')\n","        print()\n","    except:\n","      print(f'Unknown error trying to predict processing time :(')\n","  #----------------------------------------------------------------------------!\n","  last_input_video = input_video\n","  last_input_audio = input_audio\n","  shutil.copy(input_video, temp_folder)\n","  shutil.copy(input_audio, temp_folder)\n","  temp_input_video = temp_folder + input_videofile\n","  temp_input_audio = temp_folder + input_audiofile\n","\n","  #----------------------------Process the inputs!-----------------------------!\n","  print(f\"Processing {input_videofile} using {input_audiofile} for audio\")\n","  #start processing timer\n","  start_time = time.time()\n","\n","\n","  #execute Wav2Lip & upscaler\n","  !python {'static_inference.py' if input_is_image else 'inference.py'} \\\n","  --face \"{temp_input_video}\" \\\n","  --audio \"{temp_input_audio}\" \\\n","  --outfile \"{temp_output}\" \\\n","  --pads $pad_up $pad_down $pad_left $pad_right \\\n","  --checkpoint_path '/content/Easy-Wav2Lip/checkpoints/Wav2Lip.pth' \\\n","  --resize_factor $rescaleFactor \\\n","  --fps \"{fps_for_static_image}\" \\\n","  {'--nosmooth ' if nosmooth else ''} {'--no_sr ' if upscaler=='no_upscaling' else ''} {'--enhance_face gfpgan ' if upscaler == 'gfpgan' else ''} {'-w ' + str(codeformer_fidelity) + ' --enhance_face codeformer ' if upscaler == \"codeformer\" else ''} {'--sr_path ' + ESRGAN_model if upscaler == \"ESRGAN\" else ''}\n","\n","  #end processing timer and format the time it took\n","  end_time = time.time()\n","  elapsed_time = end_time - start_time\n","  process_time = int(elapsed_time)\n","  formatted_process_time = format_time(elapsed_time)\n","\n","  #rename temp file and move to correct directory\n","  if os.path.isfile(temp_output):\n","    if os.path.isfile(output_video):\n","      os.remove(output_video)\n","    !cp \"{temp_output}\" \"{output_video}\"\n","    if os.path.isfile(output_video):\n","      #show output video\n","      clear_output()\n","      print(f\"{output_filename} successfully lip synced! Find it in the same folder as your input file(s).\")\n","      if predicted_time is not None:\n","       print(f'Predicted processing time for this video was: {formatted_time} {confidence}')\n","       print(f\"Actual Processing time: {formatted_process_time}\")\n","      else:\n","       print(f\"Processing time: {formatted_process_time}\")\n","\n","    #store processing stats and upload them back to the s3 bucket\n","    try:\n","      store_processing_stats(stats_file, input_resolution, input_fps, input_length, resolution_scale, upscaler, process_time)\n","      s3.upload_file(stats_file, bucket_name, object_key)\n","      if os.path.isfile(temp_output):\n","        print(\"Loading video preview...\")\n","        showVideo(temp_output)\n","      print(f\"Processing stats have been uploaded to improve processing time predictions for everyone :)\")\n","    except:\n","      if os.path.isfile(temp_output):\n","        print(\"Loading video preview...\")\n","        showVideo(temp_output)\n","\n","  else:\n","    print(f\"Processing failed! :( see line above 👆\")\n","    process_failed = True\n","\n","  if os.path.isfile(stats_file):\n","    os.remove(stats_file)\n","  if batch_process == False:\n","    print(\"Batch Processing disabled\")\n","    if process_failed:\n","      if upscaler == \"ESRGAN\" and ESRGAN_model != default_ESRGAN_model:\n","        sys.exit(\"Processing failed - likely caused by custom ESRGAN model - try a different one!\")\n","      else:\n","        sys.exit(\"Processing failed\")\n","    else:\n","      break\n","  elif filenumber == \"\" and audio_filenumber == \"\":\n","    print('Files not set for batch processing')\n","    break\n","\n","  #Batch processing\n","  if filenumber != \"\": # if video has a filenumber\n","    match = re.search(r'\\d+', filenumber)\n","    # add 1 to video filenumber\n","    filenumber = f\"{filenumber[:match.start()]}{int(match.group())+1:0{len(match.group())}d}\"\n","\n","  if audio_filenumber != \"\": # if audio has a filenumber\n","    match = re.search(r'\\d+', audio_filenumber)\n","    # add 1 to audio filenumber\n","    audio_filenumber = f\"{audio_filenumber[:match.start()]}{int(match.group())+1:0{len(match.group())}d}\"\n","\n","  # construct input_video\n","  input_video = folder + filenamenonumber + str(filenumber) + file_type\n","  input_videofile = re.search(r\"[^\\/]+$\", input_video).group()\n","  # construct input_audio\n","  input_audio = audio_folder + audio_filenamenonumber + str(audio_filenumber) + audio_file_type\n","  input_audiofile = re.search(r\"[^\\/]+$\", input_audio).group()\n","\n","  # now check which input files exist and what to do for each scenario\n","\n","  # both +1 files exist - continue processing\n","  if os.path.exists(input_video) and os.path.exists(input_audio):\n","    continue\n","\n","  # video +1 only - continue with last audio file\n","  if os.path.exists(input_video) and input_video != last_input_video:\n","    if audio_filenumber != \"\": # if audio has a filenumber\n","        match = re.search(r'\\d+', audio_filenumber)\n","        # take 1 from audio filenumber\n","        audio_filenumber = f\"{audio_filenumber[:match.start()]}{int(match.group())-1:0{len(match.group())}d}\"\n","    continue\n","\n","  # audio +1 only - continue with last video file\n","  if os.path.exists(input_audio) and input_audio != last_input_audio:\n","    if filenumber != \"\": # if video has a filenumber\n","      match = re.search(r'\\d+', filenumber)\n","      # take 1 from video filenumber\n","      filenumber = f\"{filenumber[:match.start()]}{int(match.group())-1:0{len(match.group())}d}\"\n","    continue\n","\n","  # neither +1 files exist or current files already processed - finish processing\n","  print(\"Finished all sequentially numbered files\")\n","  if process_failed:\n","    if upscaler == \"ESRGAN\" and ESRGAN_model != default_ESRGAN_model:\n","      sys.exit(\"Processing failed - likely caused by custom ESRGAN model - try a different one!\")\n","    else:\n","      sys.exit(\"Processing failed on at least one video\")\n","  else:\n","    break"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/anothermartz/Easy-Wav2Lip/blob/v4/Easy_Wav2Lip_V4.ipynb","timestamp":1689748230298}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}